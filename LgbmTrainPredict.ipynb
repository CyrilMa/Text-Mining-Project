{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyril2/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_VECTORIZATION = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data = \"data/\"\n",
    "\n",
    "training_set = pd.read_csv(path_to_data+\"improved_training_set.csv\")\n",
    "testing_set = pd.read_csv(path_to_data+\"improved_testing_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n"
     ]
    }
   ],
   "source": [
    "selected_features = [\"description_d2v_\"+str(i)+\"_source\" for i in range(N_VECTORIZATION)]+[\"description_d2v_\"+str(i)+\"_target\" for i in range(N_VECTORIZATION)]\n",
    "selected_features += [\"title_d2v_\"+str(i)+\"_source\" for i in range(N_VECTORIZATION)]+[\"title_d2v_\"+str(i)+\"_target\" for i in range(N_VECTORIZATION)]\n",
    "selected_features += [\"common_neighbor\",\n",
    "                     \"same_cluster\",\n",
    "                     \"jaccard\",\n",
    "                     \"diff_in_bc\",\n",
    "                     \"diff_in_inlinks\",\n",
    "                     \"diff_in_year\",\n",
    "                     \"author_nb_common\",\n",
    "                     \"author_is_one_common\",\n",
    "                     \"common_classification\",\n",
    "                     \"title_is_one_common\",\n",
    "                     \"title_nb_common_word\",\n",
    "                     \"cos_similarity_title\",\n",
    "                     \"cos_similarity_description\",\n",
    "                     \"target_eccentricty\",\n",
    "                     'inlinks_target',\n",
    "                     'betweenness_author_target',\n",
    "                     'inlinks_author_target',\n",
    "                     'cos_similarity_tf_title',\n",
    "                     'cos_similarity_tf_description',\n",
    "                    ]\n",
    "\n",
    "print(len(selected_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train = training_set[selected_features],testing_set[selected_features],training_set.label\n",
    "del (training_set,testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for lgbm\n",
    "\n",
    "parameters = {\n",
    "        'application': 'binary',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'is_unbalance': 'true',\n",
    "        'boosting': 'gbdt', #'dart'\n",
    "        'num_leaves': 80,\n",
    "        'feature_fraction': 0.7,\n",
    "        'min_data_in_leaf': 500,\n",
    "        'learning_rate': 0.1,\n",
    "        'num_iterations': 500,\n",
    "        'max_bin': 255,\n",
    "        'verbosity': -2\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyril2/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score is for this fold : 0.975270259134\n"
     ]
    }
   ],
   "source": [
    "average_score = 0\n",
    "n_splits = 5\n",
    "prediction = [] #final prediction on X_test after Kfold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "for train_index, test_index in skf.split(X_train, Y_train):\n",
    "    sub_X_train, sub_X_test = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    sub_Y_train, sub_Y_test = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "        \n",
    "    lgb_train = lgb.Dataset(sub_X_train, sub_Y_train)\n",
    "    lgb_eval = lgb.Dataset(sub_X_test, sub_Y_test, reference=lgb_train)\n",
    "    \n",
    "    rfc = lgb.train(parameters,\n",
    "                       lgb_train,\n",
    "                       valid_sets=lgb_eval,\n",
    "                       num_boost_round=5000,\n",
    "                       early_stopping_rounds=100,\n",
    "                       verbose_eval=False)\n",
    "    \n",
    "    #prediction_sub is the prediction on the validation set\n",
    "    prediction_sub = rfc.predict(sub_X_test)\n",
    "    \n",
    "    #prediction_test is the prediction on the testing set\n",
    "    prediction_test = rfc.predict(X_test)\n",
    "    \n",
    "    prediction_sub = [1 if p>0.5 else 0 for p in prediction_sub]\n",
    "    \n",
    "    score_tmp = f1_score(sub_Y_test, prediction_sub)\n",
    "    average_score += score_tmp\n",
    "    print(\"f1 score is for this fold :\", score_tmp)\n",
    "    \n",
    "    # Combination with previous fold\n",
    "    if len(prediction)==0:\n",
    "        prediction = prediction_test\n",
    "    prediction += prediction_test\n",
    "        \n",
    "    del(sub_X_train, sub_X_test, sub_Y_train, sub_Y_test, prediction_sub, prediction_test)\n",
    "    \n",
    "prediction = [1 if p>=n_splits/2 else 0 for p in prediction]\n",
    "print(\"final f1 score is\", average_score/n_splits)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(prediction, columns=[\"category\"])\n",
    "df_sub.to_csv('output.csv', float_format='%.6f', index_label=\"ID\")\n",
    "\n",
    "print(\"done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
